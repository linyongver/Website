

<meta name="description" content="Yong Lin's homepage">
<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
<title>Yong Lin's Homepage</title>


<body>

    <style>
        /*********************************
         The list of publication items
         *********************************/
    /* The list of items */
    .biblist { }
    
    /* The item */
    .biblist li { }
    
    /* You can define custom styles for plstyle field here. */
    
    
    /*************************************
     The box that contain BibTeX code
     *************************************/
    div.noshow { display: none; }
    div.bibtex {
      margin-right: 0%;
      margin-top: 1.2em;
      margin-bottom: 1em;
      border: 1px solid silver;
      padding: 0em 1em;
      background: #ffffee;
    }
    div.bibtex pre { font-size: 80%; overflow: auto;  width: 100%; padding: 1em 0em;}</style>
    <script type="text/javascript">
        <!--
        // Toggle Display of BibTeX
        function toggleBibtex(articleid) {
            var bib = document.getElementById('bib_'+articleid);
            if (bib) {
                if(bib.className.indexOf('bibtex') != -1) {
                    bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex';
                }
            } else {
                return;
            }
        }
    -->
        </script>

<div id="layout-content" style="margin-top:25px">

<table>
    <tbody>
        <tr>
            <td width="670">
                <div id="toptitle">                 
                    <h1><b>Yong Lin</b>&nbsp;
                        </div>

                <h3>Ph.D. Student</h3>  
                <p>
                    <a href="https://hkust.edu.hk/" target=&ldquo;blank&rdquo;>Department of Computer Science and Engineering</a> <br>
                    <a href="https://hkust.edu.hk/" target=&ldquo;blank&rdquo;>Hong Kong  University of Science and Technology</a> <br>
                    Hong Kong<br>

                </p>
                <p>
                    <a href="https://scholar.google.com/citations?user=M4g0ZvMAAAAJ&hl=en"><b>[Google Scholar]</b></a>
                    <a href="https://github.com/linyongver" target="_blank"><b>[Github]</b></a>  <br>
                    E-mail: ylindf [at] connect [dot] ust [dot] hk<br>
                    
                </p>
            </td>
            <td>
                <!-- <img src="./files/photo.png" border="0" width="360"> -->
            </td>
        </tr><tr>
    </tr></tbody>
</table>
<h2>Short Bio</h2>
    <p> [<font color="blue"><b>Postdoc and PhD Journey</b></font>] </p> I am a incoming PostDoc Fellow at Princetion, joint hosted by <a href="https://sites.google.com/view/cjin/home" target=&ldquo;blank&rdquo;>Chi Jin</a> and <a href="https://pli.princeton.edu/" target=&ldquo;blank&rdquo;>Princeton Language Intellegence</a>. I did my PhD study and research in <a href="https://tongzhang-ml.org/" target=&ldquo;blank&rdquo;>Tong Zhang</a>'s group at the Hong Kong University of Science and Technology (HKUST). My research is generously supported by <a href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2023" target=&ldquo;blank&rdquo;>Apple AI/ML PhD fellowship</a>  and <a href="https://cerg1.ugc.edu.hk/hkpfs/index.html" target=&ldquo;blank&rdquo;>Hong Kong PhD fellowship</a> . 
    
    <p> [<font color="blue"><b>Research Interests</b></font>] My research interests include the trustworthiness and application of machine learning, for example (1) out-of-distribution (OOD) generalization, such as enabling an autonomous driving system trained on city roads to navigate country roads, and (2) alignment of AI systems, such as aligning Large Language Models (LLMs) to prioritize traits like helpfulness, harmlessness, and honesty. I developed theoretically grounded methods with strong empirical results on foundation models. More recently, I have a keen interest in Reinforcement Learning with Human Preference (RLHF). </p>
    
    <p> [<font color="blue"><b>Pre PhD Journey</b></font>] Prior to my PhD studies, I worked as a Senior Machine Learning Engineer at Alibaba (a prominent company similar to Amazon in China), where I witnessed the remarkable capabilities of machine learning and built industrial level applications with machine learning. Meanwhile, I also became aware of the inherent instability of deep models in industrial applications. </p> 



<h2>Selected Papers</h2>
<p> (* denotes equal contribution.) </p>
<ul>
    
    <h3>Pre-prints</h3>
    
    <li>
        <b>Yong Lin*</b>, Hangyu Lin*, Wei Xiong*, Shizhe Diao*,[+8 authors], Han Zhao , Nan Jiang, Heng Ji, Yuan Yao, and Tong Zhang.<br>
        <a href="https://arxiv.org/pdf/2309.06256.pdf" target=&ldquo;blank&rdquo;>Mitigating the Alignment Tax of RLHF.</a> <br>              
        ACL ARR in submission. [<a href="https://github.com/avalonstrel/AdaptiveMA" target=&ldquo;blank&rdquo;> code </a>]  <br>
    </li>

    <li>
        <b>Yong Lin*</b>, Chen Liu*, Chenlu Ye*, Qing Lian, Yuan Yao, Tong Zhang. <br>
        <a href="https://arxiv.org/abs/2309.02476" target=&ldquo;blank&rdquo;>Optimal Sample Selection Through Uncertainty Estimation and Its Application in Deep Learning.</a> <br>              
        JMLR in submission. <br>
    </li>

    <li>
        Yifan Hao*, <b>Yong Lin*</b>, Difan Zou, Tong Zhang. <br>
        <a href="https://arxiv.org/pdf/2403.17592.pdf" target=&ldquo;blank&rdquo;>On the Benefits of Over-parameterization for Out-of-Distribution Generalization.</a> <br>              
        Pre-prints.<br>
    </li>
    


    <li>
        Qizhou Wang*, <b>Yong Lin*</b>, Yongqiang Chen*, Ludwig Schmidt, Bo Han, Tong Zhang<br>
        <a href="https://counteranimal.github.io/" target=&ldquo;blank&rdquo;>Do CLIPs Always Generalize Better than ImageNet Models?</a> <br>              
        ICLM2024 in submission.<br>
    </li>
    




    
    <h3>Publications</h3>

    
    <li>
        Haoxiang Wang*, <b>Yong Lin*</b>, Wei Xiong*, Rui Yang, Shizhe Diao, Shuang Qiu, Han Zhao, Tong Zhang<br>
        <a href="https://arxiv.org/pdf/2402.18571.pdf" target=&ldquo;blank&rdquo;>Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards.</a> <br>              
        ACL 2024.<br>
    </li>

    <li>
        Hanning Zhang*, Shizhe Diao*, <b>Yong Lin*</b>, Yi R. Fung, Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji, Tong Zhang. <br>
        <a href="https://arxiv.org/pdf/2311.09677.pdf" target=&ldquo;blank&rdquo;>R-tuning: Teaching large language models to refuse unknown questions.</a> <br>              
        NAACL 2024.<br>
    </li>
    
    <li>
        <b>Yong Lin*</b>, Lu Tan*, Yifan Hao*, Honam Wong, Hanze Dong, Weizhong Zhang, Yujiu Yang, Tong Zhang. <br>
        <a href="https://arxiv.org/pdf/2309.17230.pdf" target=&ldquo;blank&rdquo;>Spurious Feature Diversification Improves Out-of-distribution Generalization.</a> <br>   
        ICLR 2024.<br>
    </li>

    <li>
        Damien Teney, <b>Yong Lin</b>, Seong Joon Oh, Ehsan Abbasnejad. <br>
        <a href="https://arxiv.org/pdf/2209.00613" target=&ldquo;blank&rdquo;>Id and ood performance are sometimes inversely correlated on real-world datasets.</a> <br>   
        NeurIPS 2023 [<font color="blue"><b>Spotlight</b></font>].<br>
    </li>

    <li>
        Rui Yang, <b>Yong Lin</b>, Xiaoteng Ma, Hao Hu, Chongjie Zhang, Tong Zhang. <br>
        <a href="https://arxiv.org/abs/2305.18882" target=&ldquo;blank&rdquo;>What Is Essential for Unseen Goal Generalization of Offline Goal-conditioned RL?</a> <br>
        ICML 2023 
    </li>

    <li>
        <b>Yong Lin*</b>, Renjie Pi*, Weizhong Zhang, Xiaobo Xia, Jiahui Gao, Xiao Zhou, Tongliang Liu, Bo Han. <br>
        <a href="https://openreview.net/forum?id=aFzaXRImWE" target=&ldquo;blank&rdquo;>A Holistic View of Noise Transition Matrix in Deep Learning and Beyond?</a> <br>
        ICLR 2023 [<font color="blue"><b>Spotlight</b></font>].
    </li>

    <li>
        <b>Yong Lin</b>, Shengyu Zhu, Lu Tan, Peng Cui. <br>
        <a href="https://openreview.net/forum?id=pUPFRSxfACD" target=&ldquo;blank&rdquo;>ZIN: When and How to Learn Invariance by Environment Inference?</a> <br>
        NeurIPS 2022 [<font color="blue"><b>Spotlight</b></font>].
    </li>
    

    <li>
        <b>Yong Lin*</b>, Hanze Dong*, Hao Wang, Tong Zhang. <br>
        <a href="https://proceedings.mlr.press/v162/zhou22d/zhou22d.pdf" target=&ldquo;blank&rdquo;>Bayesian Invariant Risk Minimization</a> <br>
        CVPR 2022 [<font color="blue"><b>Oral</b></font>].
    </li>

    <li>
        Xiao Zhou*, <b>Yong Lin*</b>, Weizhong Zhang*, Tong Zhang. <br>
        <a href="https://proceedings.mlr.press/v162/zhou22e/zhou22e.pdf" target=&ldquo;blank&rdquo;>Sparse Invariant Risk Minimization.</a> <br>
        ICML 2022.
    </li>

    <li>
        Xiao Zhou*, <b>Yong Lin*</b>, Renjie Pi*, Weizhong Zhang, Renzhe Xu, Peng Cui, Tong Zhang. <br>
        <a href="https://proceedings.mlr.press/v162/zhou22d/zhou22d.pdf" target=&ldquo;blank&rdquo;>Model Agnostic Sample Reweighting for Out-of-Distribution Learning.</a> <br>
        ICML 2022.
    </li>

    <li>
        <b>Yong Lin*</b>, Qing Lian* and Tong Zhang. <br>
        <a href="http://www.gatsby.ucl.ac.uk/~balaji/udl2021/accepted-papers/UDL2021-paper-044.pdf" target=&ldquo;blank&rdquo;>An Empirical Study of Invariant Risk Minimization on Deep Models.</a> <br>
        ICML2021 workshop on UDL.
    </li>

    <li>
        <b>Yong Lin</b>, Zheng Xu. <br>
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7063235" target=&ldquo;blank&rdquo;>Cable sheath loss reduction strategy research based on the coupled linemodel.</a> <br>
        IEEE Transactions On Power Delivery.
    </li>

</ul>


<h2>Selected Awards</h2>
<ul>
    <li>
        2023 Apple Scholars in AI/ML PhD fellowship (22 awardees all over the world).
    </li>
    <li>
        Hong Kong PhD Fellowship.
    </li>
    <li>
        National Scholarship  * 3 (1.8%, by China's Ministry of Education), 2010, 2011 and 2015.
    </li>
    
    <li>
        Outstanding Graduate of Zhejiang Province, 2013.
    </li>
</ul>




<h2>Experiences</h2>
<ul>
    <li>
        <b> The Hong Kong University of Science and Technology </b>, PhD Student, 2020 - Now.
    </li>

    <li>
        <b> Alibaba </b>, Senior Machine Learning Engineer, 2016 - 2020.
    </li>

    <li>
       <b> Zhejiang University </b>, Bachelor and Master Student (Ranking 1/207), 2009 - 2016.
    </li>
    
</ul>


<div id="footer">
    <div id="footer-text"></div>
    &copy 2024 Yong Lin | Last Update: 2024.2
</div>
</br>


</body></html>
